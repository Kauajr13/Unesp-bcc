{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kauajr13/Unesp-bcc/blob/main/IA/trabalho_agentes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nt_Y8mWLoSr2"
      },
      "id": "Nt_Y8mWLoSr2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "76863271",
      "metadata": {
        "id": "76863271"
      },
      "source": [
        "\n",
        "# Trabalho: **Meu Primeiro Agente** — Aspirador (2 salas)\n",
        "\n",
        "**Aluno(a):** Kauã Junior Silva Soares\n",
        "\n",
        "**Disciplina:** Inteligência Artificial  \n",
        "\n",
        "**Data:** 15/09/2025\n",
        "\n",
        "> **Importante:** Este notebook contém **esqueletos** com parte da solução já implementada.\n",
        "> Você deve implementar as demais funções pedidas, rodar experimentos e responder às perguntas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f8aacec",
      "metadata": {
        "id": "2f8aacec"
      },
      "source": [
        "\n",
        "## Objetivos\n",
        "1. Definir o problema via **PEAS**.  \n",
        "2. Especificar formalmente **S, A, T, h, r, P** e explicar cada símbolo.  \n",
        "3. Implementar um **agente reflexo** e medir a **performance** passo a passo.  \n",
        "4. Discutir **limitações** e propor **uma melhoria simples**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af49fab6",
      "metadata": {
        "id": "af49fab6"
      },
      "source": [
        "\n",
        "## Instruções\n",
        "- Preencha todo conteúdo solicitado (texto e código).  \n",
        "- Use a notação apresentada na aula: `s=(p,d_L,d_R)`, `o=h(s)`, `a∈A`, `r(s,a,s')`, `P`.  \n",
        "- Quando terminar, exporte em **PDF** e entregue **PDF + .ipynb** no _classroom_.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86626733",
      "metadata": {
        "id": "86626733"
      },
      "source": [
        "\n",
        "---\n",
        "## 1) PEAS — Definição do problema\n",
        "Explique concisamente e escreva as fórmulas pedidas.\n",
        "\n",
        "**P — Performance:**  \n",
        "- Defina `r(s,a,s')` e $P = \\sum_{t=0}^{H-1} r_t$\n",
        "  - `r(s,a,s')` é a recompensa recebida após a ação `a` levar do estado `s` ao estado `s′`\n",
        "  - `$P = \\sum_{t=0}^{H-1} r_t$` seria o desempenho total ao longo de H passos, sendo dessa forma a soma de todas as recompensas instantâneas\n",
        "\n",
        "- Declare os parâmetros (λ e custos).\n",
        "  - λ>0: ganho (valor) por remoção de uma unidade de sujeira\n",
        "  - os custos seriam os custos por ação realizada, no aspirador seria o custo de ir para esquerda,direita ou aspirar\n",
        "\n",
        "**E — Environment:**  \n",
        "- Descreva as duas salas, estados e por que |S| = 8.\n",
        "  - O estado s é s=(p,dL,dR) onde:\n",
        "    - p ∈ {L,R} é a posição do agente (esquerda ou direita);\n",
        "    - dL ∈ {0,1} é o bit de sujeira da sala esquerda (0=limpa, 1=suja);\n",
        "    - dR ∈ {0,1} é o bit de sujeira da sala direita (0=limpa, 1=suja);\n",
        "    - Como cada componente apresenta 2 escolhas possíveis, logo o número de estados é |S| = 2^3 = 8\n",
        "\n",
        "**A — Actuators:**  \n",
        "- Liste {ESQ, DIR, ASP} e comente custos.\n",
        "  - ESQ: move o agente para a sala da esquerda\n",
        "  - DIR: move o agente para a sala da direita\n",
        "  - ASP: aspira a sala atual, removendo a sujeira se houver\n",
        "\n",
        "  - custos:\n",
        "    - c(ESQ): custo de se mover para a esquerda\n",
        "    - c(DIR): custo de se mover para a direita\n",
        "    - c(ASP): custo de aspirar\n",
        "\n",
        "\n",
        "**S — Sensors:**  \n",
        "- Defina `h: S -> O` no modo local (`h(s)=(p, sujeira_aqui)`).\n",
        "\n",
        "  - Função de percepção: `h: S -> O` definida no modo local por `h(s)=(p, sujeira_aqui)` onde `p` é a posição do agente e `sujeira_aqui` é o bit de sujeira onde o agente está"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "600e6535",
      "metadata": {
        "id": "600e6535"
      },
      "source": [
        "\n",
        "---\n",
        "## 2) Especificação formal — S, A, T, h, r, P  **(TODO)**\n",
        "Preencha a definição com sua própria redação e notação clara.\n",
        "\n",
        "- **Estados:**  `S={(p,dL​,dR​)∣p∈{L,R},dL​∈{0,1},dR​∈{0,1}}`  \n",
        "- **Ações:**    `A = {ESQ, DIR, ASP}`  \n",
        "- **Transição determinística:** `T: S x A -> S`  \n",
        "  - `T(s,ASP) = {(L,0,dR​)}, se p=L, ou {(R,dL​,0)}, se p=R`\n",
        "  - `T(s,DIR) = (R,dL​,dR​)`\n",
        "  - `T(s,ESQ) = (L,dL,dR)`\n",
        "- **Percepção:** `h: S -> O` com observação local\n",
        "    - `h(p,dL​,dR​)=(p,dp​)`\n",
        "    - `onde dp=dL se p=L e dP = dR se p = R`\n",
        "- **Recompensa r e performance P:**\n",
        "  - λ>0: valor ganho por remover uma unidade de sujeira\n",
        "  - c(ESQ), c(DIR), c(ASP) >= 0 : custos das ações\n",
        "  - H : horizonte finito do episódio\n",
        "  - Recompensa imediata: `r(s, a, s') = λ * 1{ a = ASP  and  d_p(s) = 1  and  d_p(s') = 0 }  -  c(a)`\n",
        "\n",
        "  - Performance: `P = sum_{t=0}^{H-1} r_t onde r_t = r(s_t, a_t, s_{t+1})`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0e1de87b",
      "metadata": {
        "id": "0e1de87b"
      },
      "outputs": [],
      "source": [
        "# inicio do código\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Tuple, List, Dict, Any\n",
        "\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "49ee6882",
      "metadata": {
        "id": "49ee6882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "e937fe75-a315-4b35-fef0-f3c3cb1419dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3578463994.py, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3578463994.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    sujeira_aqui = ........\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "\n",
        "@dataclass\n",
        "class Env2Salas:\n",
        "    p: str   # 'L' ou 'R'\n",
        "    dL: int  # 0=limpo, 1=sujo\n",
        "    dR: int  # 0=limpo, 1=sujo\n",
        "\n",
        "    def copy(self):\n",
        "        sujeira_aqui = ........\n",
        "        return Env2Salas(self.p, self.dL, self.dR)\n",
        "\n",
        "    def h(self) -> Tuple[str, int]:\n",
        "        \"\"\"TODO: retornar (posicao, sujeira_aqui).\n",
        "        sujeira_aqui = dL se p=='L' senão dR.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Implemente Env2Salas.h()\")\n",
        "\n",
        "    def T(self, a: str) -> 'Env2Salas':\n",
        "        \"\"\"TODO: transição determinística.\n",
        "        a em {'ESQ','DIR','ASP'}.\n",
        "        - ASP: limpa sala atual; posição não muda\n",
        "        - DIR: p' = 'R'\n",
        "        - ESQ: p' = 'L'\n",
        "        Retorne um NOVO estado (não modifique self in-place).\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Implemente Env2Salas.T(a)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cca9655",
      "metadata": {
        "id": "0cca9655"
      },
      "outputs": [],
      "source": [
        "\n",
        "def r(s: Env2Salas, a: str, s_: Env2Salas, lam: float,\n",
        "      c_esq: float, c_dir: float, c_asp: float) -> float:\n",
        "    \"\"\"TODO: recompensa imediata.\n",
        "    r(s,a,s') = lam * 1{ASP removeu sujeira} - c(a)\n",
        "    - Dica: a indicadora é 1 quando a='ASP' e houve transição de sujo->limpo na sala atual.\n",
        "    - Caso contrário, 0.\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"Implemente r(s,a,s')\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8deaff6a",
      "metadata": {
        "id": "8deaff6a"
      },
      "outputs": [],
      "source": [
        "\n",
        "def politica_reflexo(obs: Tuple[str, int]) -> str:\n",
        "    \"\"\"TODO: política simples\n",
        "    Se sujeira_aqui == 1 => 'ASP'\n",
        "    Se sujeira_aqui == 0 => se p=='L' => 'DIR' senão 'ESQ'\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"Implemente politica_reflexo(obs)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac0af4d1",
      "metadata": {
        "id": "ac0af4d1"
      },
      "outputs": [],
      "source": [
        "\n",
        "def simular(s0: Env2Salas, lam=1.0, c_esq=1.0, c_dir=1.0, c_asp=1.0, H=20):\n",
        "    \"\"\"TODO: rode até H passos ou até (dL==0 and dR==0).\n",
        "    Retorne (historico, P), onde historico é uma lista de dicts com:\n",
        "      t, s, a, s_, r\n",
        "    \"\"\"\n",
        "    raise NotImplementedError(\"Implemente simular(...)\" )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7063209",
      "metadata": {
        "id": "d7063209"
      },
      "source": [
        "\n",
        "### Testes mínimos (rode quando terminar as implementações)\n",
        "Descomente os `assert` abaixo **depois** de implementar `h`, `T`, `r`, `politica_reflexo`, `simular`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10226c41",
      "metadata": {
        "id": "10226c41"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # --- Descomente os asserts após implementar ---\n",
        "# s = Env2Salas('L',1,1)\n",
        "# assert s.h() == ('L', 1)\n",
        "# s1 = s.T('ASP')\n",
        "# assert (s1.p, s1.dL, s1.dR) == ('L', 0, 1)\n",
        "# s2 = s1.T('DIR')\n",
        "# assert (s2.p, s2.dL, s2.dR) == ('R', 0, 1)\n",
        "\n",
        "# # Recompensas (λ=1; todos custos=1)\n",
        "# assert abs(r(s, 'ASP', s1, lam=1, c_esq=1, c_dir=1, c_asp=1) - 0.0) < 1e-9\n",
        "# assert abs(r(s1, 'DIR', s2, lam=1, c_esq=1, c_dir=1, c_asp=1) + 1.0) < 1e-9\n",
        "\n",
        "# # Política reflexo\n",
        "# assert politica_reflexo(('L',1)) == 'ASP'\n",
        "# assert politica_reflexo(('L',0)) == 'DIR'\n",
        "# assert politica_reflexo(('R',0)) == 'ESQ'\n",
        "\n",
        "# # Simulação\n",
        "# hist, P = simular(Env2Salas('L',1,1), lam=1, c_esq=1, c_dir=1, c_asp=1, H=20)\n",
        "# assert isinstance(hist, list) and len(hist) >= 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e62e0a40",
      "metadata": {
        "id": "e62e0a40"
      },
      "source": [
        "\n",
        "---\n",
        "## 4) Experimentos e Performance\n",
        "\n",
        "### Cenário A (base)\n",
        "Parâmetros: `λ=1`, `c(ESQ)=c(DIR)=c(ASP)=1`, `s0=(L,1,1)`.\n",
        "\n",
        "- Rode a simulação e mostre uma **tabela** com as colunas: `t, s, a, s_, r`.\n",
        "- Calcule o **P** final e comente o resultado (2–4 linhas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c2e0498",
      "metadata": {
        "id": "3c2e0498"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: rode o Cenário A e exiba a tabela e o P\n",
        "# s0 = Env2Salas('L',1,1)\n",
        "# hist_A, P_A = simular(s0, lam=1, c_esq=1, c_dir=1, c_asp=1, H=20)\n",
        "# pd.DataFrame(hist_A)\n",
        "# print(\"P (Cenário A) =\", P_A)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "608a789d",
      "metadata": {
        "id": "608a789d"
      },
      "source": [
        "\n",
        "### Cenário B (limpar vale mais)\n",
        "Parâmetros: `λ=2`, custos = 1. Rode e compare com o Cenário A (2–4 linhas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "679eac37",
      "metadata": {
        "id": "679eac37"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Cenário B\n",
        "# s0 = Env2Salas('L',1,1)\n",
        "# hist_B, P_B = simular(s0, lam=2, c_esq=1, c_dir=1, c_asp=1, H=20)\n",
        "# pd.DataFrame(hist_B)\n",
        "# print(\"P (Cenário B) =\", P_B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a715f31e",
      "metadata": {
        "id": "a715f31e"
      },
      "source": [
        "\n",
        "### Cenário C (movimento caro)\n",
        "Parâmetros: `λ=1`, `c(ESQ)=c(DIR)=2`, `c(ASP)=1`. Discuta o impacto (2–4 linhas).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50fc0993",
      "metadata": {
        "id": "50fc0993"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: Cenário C\n",
        "# s0 = Env2Salas('L',1,1)\n",
        "# hist_C, P_C = simular(s0, lam=1, c_esq=2, c_dir=2, c_asp=1, H=20)\n",
        "# pd.DataFrame(hist_C)\n",
        "# print(\"P (Cenário C) =\", P_C)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7433b9c7",
      "metadata": {
        "id": "7433b9c7"
      },
      "source": [
        "\n",
        "---\n",
        "## 5) Discussão e melhoria da política\n",
        "- Explique **duas limitações** do agente reflexo (sem memória).  \n",
        "- Proponha **uma melhoria simples** (ex.: 1 bit de memória) e **implemente** abaixo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8daf7d01",
      "metadata": {
        "id": "8daf7d01"
      },
      "outputs": [],
      "source": [
        "\n",
        "# TODO: implemente sua política melhorada (se precisar, crie uma memória simples)\n",
        "# def politica_melhorada(obs, mem):\n",
        "#     ...\n",
        "# def simular_melhorado(...):\n",
        "#     ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6543191d",
      "metadata": {
        "id": "6543191d"
      },
      "source": [
        "\n",
        "---\n",
        "## 6) Bônus (opcional)\n",
        "- **3 salas (L–C–R):** defina S, A, T, h e rode um cenário; calcule |S|.  \n",
        "- **Ruído de sujeira (prob. ρ):** estenda a transição e estime E[P] (média de 50 runs).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}